{
  "cells": [
    {
      "cell_type": "code",
      "id": "DEqceiuEzbJV0cM4J7UKFvJM",
      "metadata": {
        "tags": [],
        "id": "DEqceiuEzbJV0cM4J7UKFvJM"
      },
      "source": [
        "from google.cloud.dataproc_spark_connect import DataprocSparkSession\n",
        "from google.cloud.dataproc_v1 import Session\n",
        "\n",
        "# Create the Dataproc Serverless session.\n",
        "session = Session()\n",
        "# Set the session configuration for BigQuery Metastore with the Iceberg environment.\n",
        "project_id = \"[YOUR_PROJECT]\" #REPLACE\n",
        "region = \"us-central1\"\n",
        "subnet_name = \"default\"\n",
        "location = \"us-central1\"\n",
        "session.environment_config.execution_config.subnetwork_uri = f\"{subnet_name}\"\n",
        "#session.environment_config.peripherals_config.bigquery_metastore_config.project_id = f\"{project_id}\"\n",
        "#session.environment_config.peripherals_config.bigquery_metastore_config.location = f\"{location}\"\n",
        "\n",
        "warehouse_dir = \"gs://[YOUR_DIR]/warehouse\" #REPLACE\n",
        "catalog = \"biglake\"\n",
        "namespace = \"biglake_nyc\"\n",
        "\n",
        "session.runtime_config.properties[f\"spark.sql.catalog.{catalog}\"] = \"org.apache.iceberg.spark.SparkCatalog\"\n",
        "session.runtime_config.properties[f\"spark.sql.catalog.{catalog}.catalog-impl\"] = \"org.apache.iceberg.gcp.bigquery.BigQueryMetastoreCatalog\"\n",
        "session.runtime_config.properties[f\"spark.sql.catalog.{catalog}.gcp_project\"] = f\"{project_id}\"\n",
        "session.runtime_config.properties[f\"spark.sql.catalog.{catalog}.gcp_location\"] = f\"{location}\"\n",
        "session.runtime_config.properties[f\"spark.sql.catalog.{catalog}.warehouse\"] = f\"{warehouse_dir}\"\n",
        "\n",
        "\n",
        "# Create the Spark Connect session.\n",
        "spark = (\n",
        "   DataprocSparkSession.builder\n",
        "     .appName(\"sme_academy\")\n",
        "     .dataprocSessionConfig(session)\n",
        "     .getOrCreate()\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the namespace in BigQuery.\n",
        "spark.sql(f\"USE `{catalog}`;\")\n",
        "spark.sql(f\"CREATE NAMESPACE IF NOT EXISTS `{namespace}`;\")\n",
        "spark.sql(f\"USE `{namespace}`;\")\n"
      ],
      "metadata": {
        "id": "L_NtEwWWIxqY"
      },
      "id": "L_NtEwWWIxqY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Let's drop the table if exists and recreate\n",
        "spark.sql(\"DROP TABLE IF EXISTS `taxis`\");\n",
        "\n",
        "sql_query = \"\"\"\n",
        "CREATE TABLE taxis (\n",
        "  VendorID BIGINT,\n",
        "  tpep_pickup_datetime    TIMESTAMP,\n",
        "  tpep_dropoff_datetime   TIMESTAMP,\n",
        "  passenger_count         DOUBLE,\n",
        "  trip_distance           DOUBLE,\n",
        "  PULocationID            BIGINT,\n",
        "  DOLocationID            BIGINT,\n",
        "  RatecodeID              DOUBLE,\n",
        "  store_and_fwd_flag      STRING,\n",
        "  payment_type            BIGINT,\n",
        "  fare_amount             DOUBLE,\n",
        "  extra                   DOUBLE,\n",
        "  mta_tax                 DOUBLE,\n",
        "  tip_amount              DOUBLE,\n",
        "  tolls_amount            DOUBLE,\n",
        "  improvement_surcharge   DOUBLE,\n",
        "  total_amount            DOUBLE,\n",
        "  congestion_surcharge    DOUBLE,\n",
        "  airport_fee             DOUBLE,\n",
        "  tip_percentage          DOUBLE\n",
        ")\n",
        "USING iceberg\n",
        "PARTITIONED BY (tpep_pickup_datetime);\n",
        "\"\"\"\n",
        "spark.sql(sql_query)\n",
        "\n"
      ],
      "metadata": {
        "id": "GNAww6jGJNq5"
      },
      "id": "GNAww6jGJNq5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cretae temp view, alternatively can use Biglake table in BQ ### REPLACE DIR\n",
        "sql_query = \"\"\"\n",
        "CREATE OR REPLACE TEMPORARY VIEW temp_taxi_data\n",
        "USING parquet\n",
        "OPTIONS (\n",
        "  path 'gs://[YOUR_DIR]/yellow_tripdata_2025-09.parquet');\n",
        "\"\"\"\n",
        "spark.sql(sql_query)"
      ],
      "metadata": {
        "id": "C2DCHG0wJPoo"
      },
      "id": "C2DCHG0wJPoo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Insert values from temp view to iceberg table\n",
        "\n",
        "sql_query= \"\"\"\n",
        "INSERT INTO taxis\n",
        "SELECT\n",
        "  CAST(VendorID AS BIGINT),\n",
        "  tpep_pickup_datetime,\n",
        "  tpep_dropoff_datetime,\n",
        "  passenger_count,\n",
        "  trip_distance,\n",
        "  CAST(PULocationID AS BIGINT),\n",
        "  CAST(DOLocationID AS BIGINT),\n",
        "  RatecodeID,\n",
        "  store_and_fwd_flag,\n",
        "  CAST(payment_type AS BIGINT),\n",
        "  fare_amount,\n",
        "  extra,\n",
        "  mta_tax,\n",
        "  tip_amount,\n",
        "  tolls_amount,\n",
        "  improvement_surcharge,\n",
        "  total_amount,\n",
        "  congestion_surcharge,\n",
        "  airport_fee,\n",
        "  tip_amount/fare_amount\n",
        "FROM\n",
        "  temp_taxi_data\n",
        "LIMIT 1000;\n",
        "  \"\"\"\n",
        "spark.sql(sql_query)\n"
      ],
      "metadata": {
        "id": "ZZjJ4GQFN487"
      },
      "id": "ZZjJ4GQFN487",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sql_query= \"\"\"\n",
        "SELECT\n",
        "    PULocationID,\n",
        "    count(*) AS total_trips,\n",
        "    round(avg(tip_amount), 2) as avg_trip_amount,\n",
        "    -- Calculate average tip as a percentage of the fare, formatted to 2 decimal places\n",
        "    round(avg(tip_percentage) * 100, 2) AS avg_tip_percentage\n",
        "FROM\n",
        "    taxis\n",
        "WHERE\n",
        "    fare_amount > 0 AND tip_amount >= 0\n",
        "GROUP BY\n",
        "    PULocationID\n",
        "ORDER BY\n",
        "    avg_tip_percentage DESC\n",
        "LIMIT 10;\n",
        "  \"\"\"\n",
        "spark.sql(sql_query).show()"
      ],
      "metadata": {
        "id": "R2ZP0Lojxg-Y"
      },
      "id": "R2ZP0Lojxg-Y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"select * from taxis where PULocationID = 265 order by tip_amount desc limit 100;\").show()\n"
      ],
      "metadata": {
        "id": "BTFw7_bFJTNO"
      },
      "id": "BTFw7_bFJTNO",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "name": "[SME Academy Working] BigLake Apache Iceberg in BigQuery"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}